{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgY+hQj58tFQro9bjWI27Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharyupatil01/Sentiment-Analysis-Movie-Review/blob/main/Sentiment_Analysis_of_Movie_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlCmVE4J_lrf",
        "outputId": "1495d37e-8af8-4562-ec11-3de4cf993b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully\n",
            "\n",
            " First 5 row of the dataset\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "\n",
            "Information about the dataset\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ],
      "source": [
        "#Imported all the required Python libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Loading of csv file\n",
        "\n",
        "file_path=\"/content/sample_data/IMDB Dataset.csv\"\n",
        "\n",
        "# try except block is a good practice to handle potential errors\n",
        "\n",
        "try:\n",
        "  data=pd.read_csv(file_path)\n",
        "  print(\"Dataset loaded successfully\")\n",
        "  print(\"\\n First 5 row of the dataset\")\n",
        "  print(data.head())\n",
        "  print(\"\\nInformation about the dataset\")\n",
        "  data.info()\n",
        "except FileNotFoundError:\n",
        "  print(f\"File not found at path {file_path} was not found . Please make sure its in the same directory\")\n",
        "  exit()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Verifying that dataset contains the columns we need\n",
        "if 'review' in data.columns and 'sentiment' in data.columns:\n",
        "  print(\"\\n The dataset is suitable as it contains 'review' and 'sentiment' columns \")\n",
        "\n",
        "  #Preprocessing of the text data\n",
        "  print(\"\\n Preprocessing of the text data\")\n",
        "  # Defining a list of common English \"stop words\" and a function to clean the text.\n",
        "  stop_words=set(\n",
        "      [\n",
        "         'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
        "        'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
        "        'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
        "        'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
        "        'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but',\n",
        "        'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
        "        'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n",
        "        'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how',\n",
        "        'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
        "        'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\",\n",
        "        'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\",\n",
        "        'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
        "        \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\",\n",
        "        'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"\n",
        "      ]\n",
        "  )\n",
        "  def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    #this function cleans the text data by :\n",
        "    1. Ensuring the input is a string and converting it to lowercase .\n",
        "    2. Removing html tags (<br/>) that are in raw data.\n",
        "    3. Removing punctutation (like '!' , '?' etc).\n",
        "    4. Removing common English \"stop words\" from our defined list .\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    text=str(text).lower()\n",
        "    text = re.sub(r'<br />',' ',text)\n",
        "    text= ''.join([char for char in text if char not in string.punctuation])\n",
        "    text= ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "    # we apply this cleaning function to every review in the 'review' column.\n",
        "  data['cleaned_review']=data['review'].apply(preprocess_text)\n",
        "\n",
        "  print(\"\\n First 5 rows of the cleaned_review columns:\")\n",
        "\n",
        "  print(data[['review','cleaned_review']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMD8o1NOBqD7",
        "outputId": "3174fe4a-4af4-4ec9-f1a2-7206aea770e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " The dataset is suitable as it contains 'review' and 'sentiment' columns \n",
            "\n",
            " Preprocessing of the text data\n",
            "\n",
            " First 5 rows of the cleaned_review columns:\n",
            "                                              review                                     cleaned_review\n",
            "0  One of the other reviewers has mentioned that ...  one reviewers mentioned watching 1 oz episode ...\n",
            "1  A wonderful little production. <br /><br />The...  wonderful little production filming technique ...\n",
            "2  I thought this was a wonderful way to spend ti...  thought wonderful way spend time hot summer we...\n",
            "3  Basically there's a family where a little boy ...  basically theres family little boy jake thinks...\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  petter matteis love time money visually stunni...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting TEXT to Numbers\n",
        "\n",
        "#We are well aware that computer can't process the text , only numbers\n",
        "#We use TF-IDF (Term Frequency-Inverse Document Frequency) to convert each review\n",
        "# into a numberical vector , where each number represents the importance of a word .\n",
        "\n",
        "print(\"\\n Converting text to numerical data using TF-IDF\")\n",
        "\n",
        "vectorizer=TfidfVectorizer()\n",
        "X= vectorizer.fit_transform(data['cleaned_review'])\n",
        "Y=data['sentiment'] #our target labels (positive/negative)\n",
        "\n",
        "print(f\"Shape of the numerical data (TF-IDF matrix): {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU30UDKMGO1N",
        "outputId": "02f9a34a-15ef-457e-ea28-9f4731f1a7c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Converting text to numerical data using TF-IDF\n",
            "Shape of the numerical data (TF-IDF matrix): (50000, 166536)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train a MACHINE LEARNING MODEL\n",
        "# we split the data into a training ser (80%) and testing set (20%)\n",
        "#the model learns from the training data and then we test its performance on the unseen data.\n",
        "# Logistic Regression is a simple and effective model\n",
        "\n",
        "print(\"\\n Splitting the data into training and testing sets\")\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)\n",
        "model=LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train,Y_train)\n",
        "print(\"Model training is completed\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V30xg7p8HaPT",
        "outputId": "f6fc3400-4576-415d-e833-33c4338f96f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Splitting the data into training and testing sets\n",
            "Model training is completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model\n",
        "#after training , we evaluate our model's performance on text data\n",
        "#the accuracy _ score tells us what precentage of the test reviews our model\n",
        "# predicated right\n",
        "\n",
        "print(\"\\n Evaluating the model's performances\")\n",
        "y_pred=model.predict(X_test)\n",
        "accuracy=accuracy_score(Y_test,y_pred)\n",
        "print(f\"Model Accuracy on the test set :{accuracy:.2f}\")\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(Y_test,y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaQFZVQvIQkS",
        "outputId": "d3cdb095-6758-4257-c7fc-64f03d159423"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluating the model's performances\n",
            "Model Accuracy on the test set :0.90\n",
            "\n",
            " Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.91      0.88      0.90      4961\n",
            "    positive       0.89      0.91      0.90      5039\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the final and most exciting step! We test the model with a new review it has never seen.\n",
        "print(\"\\n Testing the model on a new, unseen review...\")\n",
        "new_review = [\"The movie was a masterpiece, I absolutely loved every moment of it.Highly Recommended\"]\n",
        "\n",
        "#we must apply the same cleaning and TF-IDF conversion steps to new review\n",
        "cleaned_new_review=preprocess_text(new_review[0])\n",
        "new_review_vectorized=vectorizer.transform([cleaned_new_review])\n",
        "predication=model.predict(new_review_vectorized)\n",
        "print(f\"The predicted sentiment for the new review is: {predication[0]}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeHiUTPSJJmO",
        "outputId": "0bffd842-231d-4b11-ffbc-3726663c82a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Testing the model on a new, unseen review...\n",
            "The predicted sentiment for the new review is: positive\n"
          ]
        }
      ]
    }
  ]
}